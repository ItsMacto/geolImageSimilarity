{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'mac-general (Python 3.9.15)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/pmhowe/micromamba/envs/mac-general ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletGeologyDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.labels = np.array([s[1] for s in dataset.samples])\n",
    "        self.label_to_indices = {label: np.where(self.labels == label)[0]\n",
    "                                 for label in np.unique(self.labels)}\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        anchor_img, anchor_label = self.dataset[index]\n",
    "        positive_index = index\n",
    "        # Ensure positive index is different from anchor\n",
    "        while positive_index == index:\n",
    "            positive_index = np.random.choice(self.label_to_indices[anchor_label])\n",
    "        negative_label = np.random.choice(list(set(self.label_to_indices.keys()) - set([anchor_label])))\n",
    "        negative_index = np.random.choice(self.label_to_indices[negative_label])\n",
    "        positive_img, _ = self.dataset[positive_index]\n",
    "        negative_img, _ = self.dataset[negative_index]\n",
    "        return (anchor_img, positive_img, negative_img), []\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "# Image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalizes the images\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "dataset = datasets.ImageFolder(root='data', transform=transform)\n",
    "\n",
    "# Data loader\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create triplet dataset\n",
    "triplet_dataset = TripletGeologyDataset(dataset)\n",
    "\n",
    "# Triplet data loader\n",
    "triplet_loader = DataLoader(triplet_dataset, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self, embedding_size=128):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        self.convnet = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128, embedding_size),\n",
    "            nn.BatchNorm1d(embedding_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convnet(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten to (batch_size, features)\n",
    "        x = self.fc(x)\n",
    "        x = F.normalize(x, p=2, dim=1)  # L2 normalization\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "model = EmbeddingNet()\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data_loader, optimizer, scheduler, num_epochs=20, device='cpu'):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (data, _) in enumerate(tqdm(data_loader)):\n",
    "            optimizer.zero_grad()\n",
    "            anchor, positive, negative = data\n",
    "            anchor = anchor.to(device)\n",
    "            positive = positive.to(device)\n",
    "            negative = negative.to(device)\n",
    "            anchor_out = model(anchor)\n",
    "            positive_out = model(positive)\n",
    "            negative_out = model(negative)\n",
    "            loss = triplet_loss(anchor_out, positive_out, negative_out)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        epoch_loss = running_loss / len(data_loader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type != 'cuda':\n",
    "    print('CUDA is not available. Training on CPU!')\n",
    "train_model(model, triplet_loader, optimizer, scheduler, num_epochs=20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(model, data_loader, device='cpu'):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(data_loader):\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            embeddings.append(output.cpu().numpy())\n",
    "            labels.extend(target.numpy())\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    labels = np.array(labels)\n",
    "    return embeddings, labels\n",
    "\n",
    "embeddings, labels = generate_embeddings(model, embedding_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('embeddings.npy', embeddings)\n",
    "np.save('labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of embeddings\n",
    "d = embeddings.shape[1]\n",
    "\n",
    "# Create an index\n",
    "index = faiss.IndexFlatL2(d)  # For exact search\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(embeddings.astype('float32'))  # FAISS requires float32 arrays\n",
    "print(f\"Number of vectors in the index: {index.ntotal}\")\n",
    "faiss.write_index(index, 'geology_index.faiss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index('geology_index.faiss')\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    image = Image.open(image_path)\n",
    "    if image.mode == 'RGBA':\n",
    "        image = image.convert('RGB')\n",
    "    image = transform(image)\n",
    "    return image.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "searchImagePath = './data/rhyolite/ZXB0V.jpg'\n",
    "# searchImagePath = './ben.png'\n",
    "\n",
    "query_image = preprocess_image(searchImagePath)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    query_embedding = model(query_image.to(device)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_images(indices, dataset):\n",
    "    image_paths = [dataset.samples[i][0] for i in indices[0]]\n",
    "    images = [Image.open(path) for path in image_paths]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5  # Number of nearest neighbors\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "\n",
    "similar_images = retrieve_images(indices, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(query_image_path, similar_images):\n",
    "    query_image = Image.open(query_image_path)\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, len(similar_images) + 1, 1)\n",
    "    plt.imshow(query_image, cmap='gray')\n",
    "    plt.title('Query Image')\n",
    "    plt.axis('off')\n",
    "    for i, img in enumerate(similar_images):\n",
    "        plt.subplot(1, len(similar_images) + 1, i + 2)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f'Similar Image {i+1}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_images(searchImagePath, similar_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "# embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "# plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=labels, cmap='tab10', s=5)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# tsne = TSNE(n_components=3, perplexity=30, random_state=42)\n",
    "# embeddings_3d = tsne.fit_transform(embeddings)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce embeddings to 3 dimensions\n",
    "pca = PCA(n_components=3)\n",
    "embeddings_3d = pca.fit_transform(embeddings)\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Convert labels to a color map\n",
    "unique_labels = set(labels)\n",
    "colors = plt.cm.tab10([i / len(unique_labels) for i in labels])\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot\n",
    "ax.scatter(embeddings_3d[:, 0], embeddings_3d[:, 1], embeddings_3d[:, 2],\n",
    "           c=colors, s=20, alpha=0.8)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_title(\"3D Representation of Embeddings\")\n",
    "ax.set_xlabel(\"Dimension 1\")\n",
    "ax.set_ylabel(\"Dimension 2\")\n",
    "ax.set_zlabel(\"Dimension 3\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame for Plotly\n",
    "df = pd.DataFrame({\n",
    "    'x': embeddings_3d[:, 0],\n",
    "    'y': embeddings_3d[:, 1],\n",
    "    'z': embeddings_3d[:, 2],\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "# Plot 3D scatter\n",
    "fig = px.scatter_3d(df, x='x', y='y', z='z', color='label',\n",
    "                    title=\"3D Representation of Embeddings\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
